ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/ | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   119  100   119    0     0  36346      0 --:--:-- --:--:-- --:--:-- 39666
{
  "version": "8.1.0-ccs",
  "commit": "ad96a4ab36bd815bac5069d4cc428d234a9f955a",
  "kafka_cluster_id": "TBmK1unHRFKxrYU-6y9rMQ"
}
ubuntu@ip-10-0-1-144:~$ 
ubuntu@ip-10-0-1-144:~$
ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/connector-plugins | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   417  100   417    0     0  48213      0 --:--:-- --:--:-- --:--:-- 52125
[
  {
    "class": "io.confluent.kafka.connect.datagen.DatagenConnector",
    "type": "source",
    "version": "null"
  },
  {
    "class": "org.apache.kafka.connect.mirror.MirrorCheckpointConnector",
    "type": "source",
    "version": "8.1.0-ccs"
  },
  {
    "class": "org.apache.kafka.connect.mirror.MirrorHeartbeatConnector",
    "type": "source",
    "version": "8.1.0-ccs"
  },
  {
    "class": "org.apache.kafka.connect.mirror.MirrorSourceConnector",
    "type": "source",
    "version": "8.1.0-ccs"
  }
]

ubuntu@ip-10-0-1-144:~$ curl -X PUT http://10.0.1.80:8083/connector-plugins/DatagenConnector/config/validate \
  -H "Content-Type: application/json" \
  -d '{
    "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
    "kafka.topic": "datagen-validation-test",
    "quickstart": "users",
    "tasks.max": "1"
  }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 21805    0 21628  100   177  78520    642 --:--:-- --:--:-- --:--:-- 79290
{
  "name": "io.confluent.kafka.connect.datagen.DatagenConnector",
  "error_count": 1,
  "groups": [
    "Common",
    "Transforms",
    "Predicates",
    "Error Handling",
    "Topic Creation",
    "Exactly Once Support",
    "offsets.topic"
  ],
  "configs": [
    {
      "definition": {
        "name": "name",
        "type": "STRING",
        "required": true,
        "default_value": null,
        "importance": "HIGH",
        "documentation": "Globally unique name to use for this connector.",
        "group": "Common",
        "width": "MEDIUM",
        "display_name": "Connector name",
        "dependents": [],
        "order": 1
      },
      "value": {
        "name": "name",
        "value": null,
        "recommended_values": [],
        "errors": [
          "Missing required configuration \"name\" which has no default value."
        ],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "connector.class",
        "type": "STRING",
        "required": true,
        "default_value": null,
        "importance": "HIGH",
        "documentation": "Name or alias of the class for this connector. Must be a subclass of org.apache.kafka.connect.connector.Connector. If the connector is org.apache.kafka.connect.file.FileStreamSinkConnector, you can either specify this full name,  or use \"FileStreamSink\" or \"FileStreamSinkConnector\" to make the configuration a bit shorter",
        "group": "Common",
        "width": "LONG",
        "display_name": "Connector class",
        "dependents": [],
        "order": 2
      },
      "value": {
        "name": "connector.class",
        "value": "io.confluent.kafka.connect.datagen.DatagenConnector",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "connector.plugin.version",
        "type": "STRING",
        "required": false,
        "default_value": "null",
        "importance": "MEDIUM",
        "documentation": "Version of the connector.",
        "group": "Common",
        "width": "MEDIUM",
        "display_name": "Connector version",
        "dependents": [],
        "order": 3
      },
      "value": {
        "name": "connector.plugin.version",
        "value": "null",
        "recommended_values": [
          "null"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "tasks.max",
        "type": "INT",
        "required": false,
        "default_value": "1",
        "importance": "HIGH",
        "documentation": "Maximum number of tasks to use for this connector.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Tasks max",
        "dependents": [],
        "order": 4
      },
      "value": {
        "name": "tasks.max",
        "value": "1",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "tasks.max.enforce",
        "type": "BOOLEAN",
        "required": false,
        "default_value": "true",
        "importance": "LOW",
        "documentation": "(Deprecated) Whether to enforce that the tasks.max property is respected by the connector. By default, connectors that generate too many tasks will fail, and existing sets of tasks that exceed the tasks.max property will also be failed. If this property is set to false, then connectors will be allowed to generate more than the maximum number of tasks, and existing sets of tasks that exceed the tasks.max property will be allowed to run. This property is deprecated and will be removed in an upcoming major release.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Enforce tasks max",
        "dependents": [],
        "order": 5
      },
      "value": {
        "name": "tasks.max.enforce",
        "value": "true",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "key.converter",
        "type": "CLASS",
        "required": false,
        "default_value": "org.apache.kafka.connect.json.JsonConverter",
        "importance": "LOW",
        "documentation": "Converter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the keys in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Key converter class",
        "dependents": [],
        "order": 6
      },
      "value": {
        "name": "key.converter",
        "value": "org.apache.kafka.connect.json.JsonConverter",
        "recommended_values": [
          "io.confluent.connect.avro.AvroConverter",
          "io.confluent.connect.avro.AvroConverter",
          "io.confluent.connect.json.JsonSchemaConverter",
          "io.confluent.connect.json.JsonSchemaConverter",
          "io.confluent.connect.protobuf.ProtobufConverter",
          "io.confluent.connect.protobuf.ProtobufConverter",
          "org.apache.kafka.connect.converters.BooleanConverter",
          "org.apache.kafka.connect.converters.BooleanConverter",
          "org.apache.kafka.connect.converters.ByteArrayConverter",
          "org.apache.kafka.connect.converters.ByteArrayConverter",
          "org.apache.kafka.connect.converters.DoubleConverter",
          "org.apache.kafka.connect.converters.DoubleConverter",
          "org.apache.kafka.connect.converters.FloatConverter",
          "org.apache.kafka.connect.converters.FloatConverter",
          "org.apache.kafka.connect.converters.IntegerConverter",
          "org.apache.kafka.connect.converters.IntegerConverter",
          "org.apache.kafka.connect.converters.LongConverter",
          "org.apache.kafka.connect.converters.LongConverter",
          "org.apache.kafka.connect.converters.ShortConverter",
          "org.apache.kafka.connect.converters.ShortConverter",
          "org.apache.kafka.connect.json.JsonConverter",
          "org.apache.kafka.connect.json.JsonConverter",
          "org.apache.kafka.connect.storage.StringConverter",
          "org.apache.kafka.connect.storage.StringConverter"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "key.converter.plugin.version",
        "type": "STRING",
        "required": false,
        "default_value": "8.1.0-ccs",
        "importance": "LOW",
        "documentation": "Version of the key converter.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Key converter version",
        "dependents": [],
        "order": 7
      },
      "value": {
        "name": "key.converter.plugin.version",
        "value": "8.1.0-ccs",
        "recommended_values": [
          "8.1.0-ccs"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "value.converter",
        "type": "CLASS",
        "required": false,
        "default_value": "org.apache.kafka.connect.json.JsonConverter",
        "importance": "LOW",
        "documentation": "Converter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the values in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Value converter class",
        "dependents": [],
        "order": 8
      },
      "value": {
        "name": "value.converter",
        "value": "org.apache.kafka.connect.json.JsonConverter",
        "recommended_values": [
          "io.confluent.connect.avro.AvroConverter",
          "io.confluent.connect.avro.AvroConverter",
          "io.confluent.connect.json.JsonSchemaConverter",
          "io.confluent.connect.json.JsonSchemaConverter",
          "io.confluent.connect.protobuf.ProtobufConverter",
          "io.confluent.connect.protobuf.ProtobufConverter",
          "org.apache.kafka.connect.converters.BooleanConverter",
          "org.apache.kafka.connect.converters.BooleanConverter",
          "org.apache.kafka.connect.converters.ByteArrayConverter",
          "org.apache.kafka.connect.converters.ByteArrayConverter",
          "org.apache.kafka.connect.converters.DoubleConverter",
          "org.apache.kafka.connect.converters.DoubleConverter",
          "org.apache.kafka.connect.converters.FloatConverter",
          "org.apache.kafka.connect.converters.FloatConverter",
          "org.apache.kafka.connect.converters.IntegerConverter",
          "org.apache.kafka.connect.converters.IntegerConverter",
          "org.apache.kafka.connect.converters.LongConverter",
          "org.apache.kafka.connect.converters.LongConverter",
          "org.apache.kafka.connect.converters.ShortConverter",
          "org.apache.kafka.connect.converters.ShortConverter",
          "org.apache.kafka.connect.json.JsonConverter",
          "org.apache.kafka.connect.json.JsonConverter",
          "org.apache.kafka.connect.storage.StringConverter",
          "org.apache.kafka.connect.storage.StringConverter"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "value.converter.plugin.version",
        "type": "STRING",
        "required": false,
        "default_value": "8.1.0-ccs",
        "importance": "LOW",
        "documentation": "Version of the value converter.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Value converter version",
        "dependents": [],
        "order": 9
      },
      "value": {
        "name": "value.converter.plugin.version",
        "value": "8.1.0-ccs",
        "recommended_values": [
          "8.1.0-ccs"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "header.converter",
        "type": "CLASS",
        "required": false,
        "default_value": "org.apache.kafka.connect.storage.SimpleHeaderConverter",
        "importance": "LOW",
        "documentation": "HeaderConverter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the header values in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro. By default, the SimpleHeaderConverter is used to serialize header values to strings and deserialize them by inferring the schemas.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Header converter class",
        "dependents": [],
        "order": 10
      },
      "value": {
        "name": "header.converter",
        "value": "org.apache.kafka.connect.storage.SimpleHeaderConverter",
        "recommended_values": [
          "org.apache.kafka.connect.converters.BooleanConverter",
          "org.apache.kafka.connect.converters.BooleanConverter",
          "org.apache.kafka.connect.converters.ByteArrayConverter",
          "org.apache.kafka.connect.converters.ByteArrayConverter",
          "org.apache.kafka.connect.converters.DoubleConverter",
          "org.apache.kafka.connect.converters.DoubleConverter",
          "org.apache.kafka.connect.converters.FloatConverter",
          "org.apache.kafka.connect.converters.FloatConverter",
          "org.apache.kafka.connect.converters.IntegerConverter",
          "org.apache.kafka.connect.converters.IntegerConverter",
          "org.apache.kafka.connect.converters.LongConverter",
          "org.apache.kafka.connect.converters.LongConverter",
          "org.apache.kafka.connect.converters.ShortConverter",
          "org.apache.kafka.connect.converters.ShortConverter",
          "org.apache.kafka.connect.json.JsonConverter",
          "org.apache.kafka.connect.json.JsonConverter",
          "org.apache.kafka.connect.storage.SimpleHeaderConverter",
          "org.apache.kafka.connect.storage.SimpleHeaderConverter",
          "org.apache.kafka.connect.storage.StringConverter",
          "org.apache.kafka.connect.storage.StringConverter"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "header.converter.plugin.version",
        "type": "STRING",
        "required": false,
        "default_value": "8.1.0-ccs",
        "importance": "LOW",
        "documentation": "Version of the header converter.",
        "group": "Common",
        "width": "SHORT",
        "display_name": "Header converter version",
        "dependents": [],
        "order": 11
      },
      "value": {
        "name": "header.converter.plugin.version",
        "value": "8.1.0-ccs",
        "recommended_values": [
          "8.1.0-ccs"
        ],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "transforms",
        "type": "LIST",
        "required": false,
        "default_value": "",
        "importance": "LOW",
        "documentation": "Aliases for the transformations to be applied to records.",
        "group": "Transforms",
        "width": "LONG",
        "display_name": "Transforms",
        "dependents": [],
        "order": 12
      },
      "value": {
        "name": "transforms",
        "value": "",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "predicates",
        "type": "LIST",
        "required": false,
        "default_value": "",
        "importance": "LOW",
        "documentation": "Aliases for the predicates used by transformations.",
        "group": "Predicates",
        "width": "LONG",
        "display_name": "Predicates",
        "dependents": [],
        "order": 13
      },
      "value": {
        "name": "predicates",
        "value": "",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "config.action.reload",
        "type": "STRING",
        "required": false,
        "default_value": "restart",
        "importance": "LOW",
        "documentation": "The action that Connect should take on the connector when changes in external configuration providers result in a change in the connector's configuration properties. A value of 'none' indicates that Connect will do nothing. A value of 'restart' indicates that Connect should restart/reload the connector with the updated configuration properties.The restart may actually be scheduled in the future if the external configuration provider indicates that a configuration value will expire in the future.",
        "group": "Common",
        "width": "MEDIUM",
        "display_name": "Reload Action",
        "dependents": [],
        "order": 14
      },
      "value": {
        "name": "config.action.reload",
        "value": "restart",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "errors.retry.timeout",
        "type": "LONG",
        "required": false,
        "default_value": "0",
        "importance": "MEDIUM",
        "documentation": "The maximum duration in milliseconds that a failed operation will be reattempted. The default is 0, which means no retries will be attempted. Use -1 for infinite retries.",
        "group": "Error Handling",
        "width": "MEDIUM",
        "display_name": "Retry Timeout for Errors",
        "dependents": [],
        "order": 1
      },
      "value": {
        "name": "errors.retry.timeout",
        "value": "0",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "errors.retry.delay.max.ms",
        "type": "LONG",
        "required": false,
        "default_value": "60000",
        "importance": "MEDIUM",
        "documentation": "The maximum duration in milliseconds between consecutive retry attempts. Jitter will be added to the delay once this limit is reached to prevent thundering herd issues.",
        "group": "Error Handling",
        "width": "MEDIUM",
        "display_name": "Maximum Delay Between Retries for Errors",
        "dependents": [],
        "order": 2
      },
      "value": {
        "name": "errors.retry.delay.max.ms",
        "value": "60000",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "errors.tolerance",
        "type": "STRING",
        "required": false,
        "default_value": "none",
        "importance": "MEDIUM",
        "documentation": "Behavior for tolerating errors during connector operation. 'none' is the default value and signals that any error will result in an immediate connector task failure; 'all' changes the behavior to skip over problematic records.",
        "group": "Error Handling",
        "width": "SHORT",
        "display_name": "Error Tolerance",
        "dependents": [],
        "order": 3
      },
      "value": {
        "name": "errors.tolerance",
        "value": "none",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "errors.log.enable",
        "type": "BOOLEAN",
        "required": false,
        "default_value": "false",
        "importance": "MEDIUM",
        "documentation": "If true, write each error and the details of the failed operation and problematic record to the Connect application log. This is 'false' by default, so that only errors that are not tolerated are reported.",
        "group": "Error Handling",
        "width": "SHORT",
        "display_name": "Log Errors",
        "dependents": [],
        "order": 4
      },
      "value": {
        "name": "errors.log.enable",
        "value": "false",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "errors.log.include.messages",
        "type": "BOOLEAN",
        "required": false,
        "default_value": "false",
        "importance": "MEDIUM",
        "documentation": "Whether to include in the log the Connect record that resulted in a failure. For sink records, the topic, partition, offset, and timestamp will be logged. For source records, the key and value (and their schemas), all headers, and the timestamp, Kafka topic, Kafka partition, source partition, and source offset will be logged. This is 'false' by default, which will prevent record keys, values, and headers from being written to log files.",   
        "group": "Error Handling",
        "width": "SHORT",
        "display_name": "Log Error Details",
        "dependents": [],
        "order": 5
      },
      "value": {
        "name": "errors.log.include.messages",
        "value": "false",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "topic.creation.groups",
        "type": "LIST",
        "required": false,
        "default_value": "",
        "importance": "LOW",
        "documentation": "Groups of configurations for topics created by source connectors",
        "group": "Topic Creation",
        "width": "LONG",
        "display_name": "Topic Creation Groups",
        "dependents": [],
        "order": 1
      },
      "value": {
        "name": "topic.creation.groups",
        "value": "",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "exactly.once.support",
        "type": "STRING",
        "required": false,
        "default_value": "requested",
        "importance": "MEDIUM",
        "documentation": "Permitted values are requested, required. If set to \"required\", forces a preflight check for the connector to ensure that it can provide exactly-once semantics with the given configuration. Some connectors may be capable of providing exactly-once semantics but not signal to Connect that they support this; in that case, documentation for the connector should be consulted carefully before creating it, and the value for this property should be set to \"requested\". Additionally, if the value is set to \"required\" but the worker that performs preflight validation does not have exactly-once support enabled for source connectors, requests to create or validate the connector will fail.",
        "group": "Exactly Once Support",
        "width": "SHORT",
        "display_name": "Exactly once support",
        "dependents": [],
        "order": 2
      },
      "value": {
        "name": "exactly.once.support",
        "value": "requested",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "transaction.boundary",
        "type": "STRING",
        "required": false,
        "default_value": "poll",
        "importance": "MEDIUM",
        "documentation": "Permitted values are: poll, interval, connector. If set to 'poll', a new producer transaction will be started and committed for every batch of records that each task from this connector provides to Connect. If set to 'connector', relies on connector-defined transaction boundaries; note that not all connectors are capable of defining their own transaction boundaries, and in that case, attempts to instantiate a connector with this value will fail. Finally, if set to 'interval', commits transactions only after a user-defined time interval has passed.",
        "group": "Exactly Once Support",
        "width": "SHORT",
        "display_name": "Transaction Boundary",
        "dependents": [],
        "order": 3
      },
      "value": {
        "name": "transaction.boundary",
        "value": "poll",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "transaction.boundary.interval.ms",
        "type": "LONG",
        "required": false,
        "default_value": null,
        "importance": "LOW",
        "documentation": "If 'transaction.boundary' is set to 'interval', determines the interval for producer transaction commits by connector tasks. If unset, defaults to the value of the worker-level 'offset.flush.interval.ms' property. It has no effect if a different transaction.boundary is specified.",      
        "group": "Exactly Once Support",
        "width": "SHORT",
        "display_name": "Transaction boundary interval",
        "dependents": [],
        "order": 4
      },
      "value": {
        "name": "transaction.boundary.interval.ms",
        "value": null,
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "offsets.storage.topic",
        "type": "STRING",
        "required": false,
        "default_value": null,
        "importance": "LOW",
        "documentation": "The name of a separate offsets topic to use for this connector. If empty or not specified, the workerâ€™s global offsets topic name will be used. If specified, the offsets topic will be created if it does not already exist on the Kafka cluster targeted by this connector (which may be different from the one used for the worker's global offsets topic if the bootstrap.servers property of the connector's producer has been overridden from the worker's). Only applicable in distributed mode; in standalone mode, setting this property will have no effect.",
        "group": "offsets.topic",
        "width": "LONG",
        "display_name": "Offsets topic",
        "dependents": [],
        "order": 1
      },
      "value": {
        "name": "offsets.storage.topic",
        "value": null,
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "kafka.topic",
        "type": "STRING",
        "required": true,
        "default_value": null,
        "importance": "HIGH",
        "documentation": "Topic to write to",
        "group": null,
        "width": "NONE",
        "display_name": "kafka.topic",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "kafka.topic",
        "value": "datagen-validation-test",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "max.interval",
        "type": "LONG",
        "required": false,
        "default_value": "500",
        "importance": "HIGH",
        "documentation": "Max interval between messages (ms)",
        "group": null,
        "width": "NONE",
        "display_name": "max.interval",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "max.interval",
        "value": "500",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "iterations",
        "type": "INT",
        "required": false,
        "default_value": "-1",
        "importance": "HIGH",
        "documentation": "Number of messages to send from each task, or less than 1 for unlimited",
        "group": null,
        "width": "NONE",
        "display_name": "iterations",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "iterations",
        "value": "-1",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "schema.string",
        "type": "STRING",
        "required": false,
        "default_value": "",
        "importance": "HIGH",
        "documentation": "The literal JSON-encoded Avro schema to use",
        "group": null,
        "width": "NONE",
        "display_name": "schema.string",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "schema.string",
        "value": "",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "schema.filename",
        "type": "STRING",
        "required": false,
        "default_value": "",
        "importance": "HIGH",
        "documentation": "Filename of schema to use",
        "group": null,
        "width": "NONE",
        "display_name": "schema.filename",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "schema.filename",
        "value": "",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "schema.keyfield",
        "type": "STRING",
        "required": false,
        "default_value": "",
        "importance": "HIGH",
        "documentation": "Name of field to use as the message key",
        "group": null,
        "width": "NONE",
        "display_name": "schema.keyfield",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "schema.keyfield",
        "value": "",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "quickstart",
        "type": "STRING",
        "required": false,
        "default_value": "",
        "importance": "HIGH",
        "documentation": "Name of quickstart to use",
        "group": null,
        "width": "NONE",
        "display_name": "quickstart",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "quickstart",
        "value": "users",
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    },
    {
      "definition": {
        "name": "random.seed",
        "type": "LONG",
        "required": false,
        "default_value": null,
        "importance": "LOW",
        "documentation": "Numeric seed for generating random data. Two connectors started with the same seed will deterministically produce the same data. Each task will generate different data than the other tasks in the same connector.",
        "group": null,
        "width": "NONE",
        "display_name": "random.seed",
        "dependents": [],
        "order": -1
      },
      "value": {
        "name": "random.seed",
        "value": null,
        "recommended_values": [],
        "errors": [],
        "visible": true
      }
    }
  ]
}
ubuntu@ip-10-0-1-144:~$ ^C
ubuntu@ip-10-0-1-144:~$ curl -X POST http://10.0.1.80:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "datagen-crud-test",
    "config": {
      "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
      "kafka.topic": "datagen-users-crud",
      "quickstart": "users",
      "key.converter": "org.apache.kafka.connect.storage.StringConverter",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "false",
      "max.interval": "1000",
      "iterations": "10000000",
      "tasks.max": "1"
    }
  }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   948  100   455  100   493   5244   5682 --:--:-- --:--:-- --:--:-- 11023
{
  "name": "datagen-crud-test",
  "config": {
    "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
    "kafka.topic": "datagen-users-crud",
    "quickstart": "users",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "max.interval": "1000",
    "iterations": "10000000",
    "tasks.max": "1",
    "name": "datagen-crud-test"
  },
  "tasks": [],
  "type": "source"
}
ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/connectors | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    68  100    68    0     0   6878      0 --:--:-- --:--:-- --:--:--  7555
[
  "simple-http-source",
  "datagen-crud-test",
  "http-source-topics-list"
]
ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/connectors/datagen-crud-test/status | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   267  100   267    0     0  27905      0 --:--:-- --:--:-- --:--:-- 29666
{
  "name": "datagen-crud-test",
  "connector": {
    "state": "RUNNING",
    "worker_id": "ip-10-0-1-80.eu-central-1.compute.internal:8083",
    "version": null
  },
  "tasks": [
    {
      "id": 0,
      "state": "RUNNING",
      "worker_id": "ip-10-0-1-80.eu-central-1.compute.internal:8083",
      "version": null
    }
  ],
  "type": "source"
}
ubuntu@ip-10-0-1-144:~$ curl -X PUT http://10.0.1.80:8083/connectors/datagen-crud-test/config \
  -H "Content-Type: application/json" \
  -d '{
    "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
    "kafka.topic": "datagen-users-crud",
    "quickstart": "users",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "max.interval": "500",
    "iterations": "10000000",
    "tasks.max": "1"
  }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   915  100   496  100   419  13249  11192 --:--:-- --:--:-- --:--:-- 24729
{
  "name": "datagen-crud-test",
  "config": {
    "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
    "kafka.topic": "datagen-users-crud",
    "quickstart": "users",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "max.interval": "500",
    "iterations": "10000000",
    "tasks.max": "1",
    "name": "datagen-crud-test"
  },
  "tasks": [
    {
      "connector": "datagen-crud-test",
      "task": 0
    }
  ],
  "type": "source"
}
ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/connectors/datagen-crud-test/tasks | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   526  100   526    0     0  61592      0 --:--:-- --:--:-- --:--:-- 65750
[
  {
    "id": {
      "connector": "datagen-crud-test",
      "task": 0
    },
    "config": {
      "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
      "quickstart": "users",
      "task.class": "io.confluent.kafka.connect.datagen.DatagenTask",
      "tasks.max": "1",
      "value.converter.schemas.enable": "false",
      "name": "datagen-crud-test",
      "kafka.topic": "datagen-users-crud",
      "task.id": "0",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "max.interval": "500",
      "key.converter": "org.apache.kafka.connect.storage.StringConverter",
      "iterations": "10000000"
    }
  }
]
ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/connectors/datagen-crud-test/tasks/0/status | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   103  100   103    0     0  12705      0 --:--:-- --:--:-- --:--:-- 14714
{
  "id": 0,
  "state": "RUNNING",
  "worker_id": "ip-10-0-1-80.eu-central-1.compute.internal:8083",
  "version": null
}
ubuntu@ip-10-0-1-144:~$ curl -X POST http://10.0.1.80:8083/connectors/datagen-crud-test/tasks/0/restart
ubuntu@ip-10-0-1-144:~$ curl -X DELETE http://10.0.1.80:8083/connectors/datagen-crud-test
ubuntu@ip-10-0-1-144:~$ curl -X GET http://10.0.1.80:8083/connectors | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    48  100    48    0     0  13245      0 --:--:-- --:--:-- --:--:-- 16000
[
  "simple-http-source",
  "http-source-topics-list"
]
ubuntu@ip-10-0-1-144:~$