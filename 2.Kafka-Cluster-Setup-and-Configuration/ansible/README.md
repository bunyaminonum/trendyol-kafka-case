# Kafka Cluster Setup and Configuration

## Overview

This section deploys a production-ready Apache Kafka cluster in **KRaft mode** (without ZooKeeper) using Confluent Platform Ansible Collection (`cp-ansible`). The cluster is configured with enterprise-grade security, JMX monitoring, and rack awareness across multiple availability zones.

## Architecture

### Cluster Topology

**Kafka Brokers (4 nodes)**

- `10.0.1.7` - Broker 1 (AZ-1, node_id: 1)
- `10.0.1.244` - Broker 2 (AZ-1, node_id: 2)
- `10.0.2.185` - Broker 3 (AZ-2, node_id: 3)
- `10.0.2.91` - Broker 4 (AZ-2, node_id: 4)

**Kafka Controllers (3 nodes)**

- `10.0.1.240` - Controller 1 (AZ-1, controller_id: 3001)
- `10.0.2.70` - Controller 2 (AZ-2, controller_id: 3002)
- `10.0.3.250` - Controller 3 (AZ-3, controller_id: 3003)

**Kafka Connect (1 node)**

- `10.0.1.80` - Kafka Connect (AZ-1)

### KRaft Mode Configuration

- **Process Roles**: Separated architecture
  - Controllers: `process.roles=controller`
  - Brokers: `process.roles=broker`
- **Quorum Voters**: All 3 controllers form the metadata quorum
- **No ZooKeeper**: Modern Kafka architecture without ZooKeeper dependency

## Security Configuration

### Method 2: Production-Grade Security (SASL_SSL + SCRAM-SHA-512)

✅ **Implemented Security Features:**

1. **SSL/TLS Encryption**

   - Self-signed certificates generated by cp-ansible
   - All inter-broker and client communication encrypted
   - Certificate Authority (CA) automatically generated
2. **SASL Authentication**

   - **Mechanism**: SCRAM-SHA-512 (Salted Challenge Response Authentication Mechanism)
   - **Protocol**: SASL_SSL
   - **Inter-broker**: SCRAM-SHA-512
3. **User Credentials**

   ```yaml
   sasl_scram_users:
     admin: admin-secret-password
     client: client-secret-password
     kafka_connect: kafka_connect-secret
   ```
4. **Controller Security**

   - Uses PLAIN mechanism for controller quorum communication
   - Separate listener configuration for controller-to-controller traffic

## Listener Configuration

### Broker Listeners

- **INTERNAL** (Port 9092)
  - SSL enabled
  - SASL_SCRAM authentication
  - Used for inter-broker and client communication

### Controller Listeners

- **CONTROLLER** (Port 9093)
  - SSL enabled
  - SASL_PLAIN authentication
  - Used for controller quorum communication

## JMX Configuration

All brokers and controllers are configured with JMX exporters for Prometheus monitoring:

- **Brokers**: JMX metrics exposed on port 8080
- **Controllers**: JMX metrics exposed on port 8079
- **Kafka Connect**: JMX metrics exposed on port 8079

## Prerequisites

### 1. Ansible Control Node Setup

Install required tools:

```bash
connect to bastion host:
ssh -i "kafka-key.pem" ubuntu@3.123.35.145
sudo apt-get update
sudo apt-get install -y python3-pip software-properties-common git
Which services should be restarted? :
[x] networkd-dispatcher.service 
[x] unattended-upgrades.service 
space(x) + down + space + tab + enter (ok) 

install ansbile:
sudo add-apt-repository --yes --update ppa:ansible/ansible
sudo apt-get install -y ansible	

install confluent platform with ansible-galaxy:

mkdir kafka-deploy
cd kafka-deploy
vi hosts.yml

vi ansible.cfg
[defaults]
hash_behaviour = merge
host_key_checking = False

on windows terminal:
scp -i "kafka-key.pem" kafka-key.pem ubuntu@3.123.35.145:/home/ubuntu/kafka-key.pem

on bastion host terminal:
chmod 400 /home/ubuntu/kafka-key.pem
ansible-playbook -i hosts.yml confluent.platform.all -vvv
```

### 2. SSH Key Configuration

Ensure SSH key (`kafka-key.pem`) is available:

```bash
chmod 400 /home/ubuntu/kafka-key.pem
```

### 3. Update Inventory

Edit `ansible/hosts.yml` with actual IP addresses from Terraform outputs.

## Deployment

### Step 1: Navigate to Ansible Directory

```bash
cd "2.Kafka-Cluster-Setup-and-Configuration/ansible"
```

### Step 2: Verify Connectivity

```bash
ansible all -m ping
```

Expected output: `pong` from all hosts

### Step 3: Deploy Kafka Cluster

```bash
ansible-playbook -i hosts.yml confluent.platform.all
```

Deployment takes approximately **15-20 minutes**.

### Step 4: Verify Installation

**Check Broker Status:**

```bash
ssh -i /home/ubuntu/kafka-key.pem ubuntu@10.0.1.7
sudo systemctl status confluent-kafka
```

**Check Controller Status:**

```bash
ssh -i /home/ubuntu/kafka-key.pem ubuntu@10.0.1.240
sudo systemctl status confluent-kcontroller
```

## Post-Deployment Verification

### 1. Cluster Metadata

```bash
# On any broker node
kafka-metadata-shell --snapshot /var/lib/controller/data/__cluster_metadata-0/*.log
```

### 2. Create Test Topic

```bash
kafka-topics --create \
  --bootstrap-server 10.0.1.7:9092 \
  --command-config /etc/kafka/client.properties \
  --topic test-topic \
  --partitions 3 \
  --replication-factor 3
```

### 3. List Topics

```bash
kafka-topics --list \
  --bootstrap-server 10.0.1.7:9092 \
  --command-config /etc/kafka/client.properties
```

## Configuration Files

### Ansible Inventory Structure

```
ansible/
├── ansible.cfg          # Ansible behavior configuration
└── hosts.yml            # Inventory with all nodes and variables
```

### Key Variables in hosts.yml

| Variable                | Value         | Description                    |
| ----------------------- | ------------- | ------------------------------ |
| `ssl_enabled`         | true          | Enable SSL/TLS encryption      |
| `ssl_self_signed`     | true          | Use self-signed certificates   |
| `sasl_protocol`       | scram         | SASL mechanism                 |
| `sasl_mechanism`      | SCRAM-SHA-512 | Authentication method          |
| `jmxexporter_enabled` | true          | Enable Prometheus JMX exporter |

## Design Decisions

1. **KRaft Mode**: Eliminates ZooKeeper complexity and improves scalability
2. **Separated Controller/Broker Roles**: Dedicated controllers for better metadata management
3. **SCRAM-SHA-512**: Strong authentication without external dependencies
4. **Self-Signed Certificates**: Simplifies deployment; production should use CA-signed certificates
5. **Rack Awareness**: Distributes replicas across availability zones for fault tolerance

## Troubleshooting

### Issue: Ansible playbook fails with connection timeout

**Solution**: Verify security group allows traffic between nodes and SSH access

### Issue: SSL handshake failure

**Solution**: Regenerate certificates by setting:

```yaml
regenerate_ca: true
regenerate_keystore_and_truststore: true
```

### Issue: SASL authentication failure

**Solution**: Verify user credentials in `hosts.yml` match client configuration

### Issue: Controller quorum not forming

**Solution**: Check `kafka_controller_quorum_voters` contains all controller hostnames and ports

## Important Notes

**Security Considerations:**

- Self-signed certificates are used for simplicity
- In production, use certificates signed by a trusted CA
- Store sensitive credentials in Ansible Vault
- Rotate SASL credentials regularly

**Performance Tuning:**

- Default configurations are suitable for development/testing
- Production workloads require tuning based on throughput requirements
- Consider increasing `num.io.threads`, `num.network.threads`, and heap sizes

## Next Steps

After successful cluster deployment:

1. Configure monitoring in **Section 3: Observability**
2. Deploy REST API in **Section 4: Operation Excellence**
3. Set up Kafka Connect in **Section 5: Kafka Connect Cluster**
